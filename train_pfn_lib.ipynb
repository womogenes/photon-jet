{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "843dcef2-6057-4b87-aa65-80527ab8d20f",
   "metadata": {},
   "source": [
    "## Train a PFN using the `energyflow` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbf3f198-9b94-49e5-a8ab-3ed6c9ceb74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 04:15:18.090927: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-30 04:15:19.916001: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "import energyflow as ef\n",
    "from energyflow.archs import PFN\n",
    "\n",
    "from data import get_data\n",
    "from utils import model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89ae1c3c-a088-471c-b2c2-3cb9f6383a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"scalar1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f29243f-375d-4b31-b2af-c6979b997f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_val, X_test,\n",
    " Y_train, Y_val, Y_test) = get_data(task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12ecaa02-455a-4943-b637-6baba4bfd460",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 04:15:35.633431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15363 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:81:00.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, None, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " tdist_0 (TimeDistributed)      (None, None, 256)    1280        ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, None, 256)    0           ['tdist_0[0][0]']                \n",
      "                                                                                                  \n",
      " tdist_1 (TimeDistributed)      (None, None, 256)    65792       ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, None, 256)    0           ['tdist_1[0][0]']                \n",
      "                                                                                                  \n",
      " tdist_2 (TimeDistributed)      (None, None, 256)    65792       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, None, 256)    0           ['tdist_2[0][0]']                \n",
      "                                                                                                  \n",
      " tdist_3 (TimeDistributed)      (None, None, 256)    65792       ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, None, 256)    0           ['tdist_3[0][0]']                \n",
      "                                                                                                  \n",
      " tdist_4 (TimeDistributed)      (None, None, 128)    32896       ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, None, 128)    0           ['tdist_4[0][0]']                \n",
      "                                                                                                  \n",
      " tdist_5 (TimeDistributed)      (None, None, 128)    16512       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, None, 128)    0           ['tdist_5[0][0]']                \n",
      "                                                                                                  \n",
      " tdist_6 (TimeDistributed)      (None, None, 128)    16512       ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, None, 128)    0           ['tdist_6[0][0]']                \n",
      "                                                                                                  \n",
      " tdist_7 (TimeDistributed)      (None, None, 128)    16512       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " mask (Lambda)                  (None, None)         0           ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, None, 128)    0           ['tdist_7[0][0]']                \n",
      "                                                                                                  \n",
      " sum (Dot)                      (None, 128)          0           ['mask[0][0]',                   \n",
      "                                                                  'activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " dense_0 (Dense)                (None, 256)          33024       ['sum[0][0]']                    \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 256)          0           ['dense_0[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 256)          65792       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 256)          0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 256)          65792       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 256)          0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 256)          65792       ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 256)          0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 128)          32896       ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 128)          0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 128)          16512       ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 128)          0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 128)          16512       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 128)          0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 128)          16512       ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 128)          0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 3)            387         ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 3)            0           ['output[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 594,307\n",
      "Trainable params: 594,307\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Phi_sizes = (256,) * 4 + (128,) * 4\n",
    "F_sizes = (256,) * 4 + (128,) * 4\n",
    "pfn = PFN(\n",
    "    input_dim=X_train.shape[-1],\n",
    "    output_dim=3,\n",
    "    Phi_sizes=Phi_sizes,\n",
    "    F_sizes=F_sizes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ef290c5-a215-4550-8fb3-987e0d2b013d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 04:15:43.229925: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x2ab87f85c8f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-08-30 04:15:43.229971: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "2023-08-30 04:15:43.235427: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-08-30 04:15:43.419271: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-08-30 04:15:43.669308: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100/2100 [==============================] - 123s 56ms/step - loss: 1006.3250 - acc: 0.3331 - val_loss: 71.5366 - val_acc: 0.3356\n",
      "Epoch 2/45\n",
      "2100/2100 [==============================] - 114s 54ms/step - loss: 123.5246 - acc: 0.3319 - val_loss: 353.4251 - val_acc: 0.3328\n",
      "Epoch 3/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 21.1734 - acc: 0.3355 - val_loss: 3.8645 - val_acc: 0.3317\n",
      "Epoch 4/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 28.4510 - acc: 0.3355 - val_loss: 33.9031 - val_acc: 0.3316\n",
      "Epoch 5/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 8.0378 - acc: 0.3365 - val_loss: 1.3414 - val_acc: 0.3356\n",
      "Epoch 6/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 5.0634 - acc: 0.3357 - val_loss: 1.3316 - val_acc: 0.3316\n",
      "Epoch 7/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 1.1637 - acc: 0.3587 - val_loss: 1.2956 - val_acc: 0.3341\n",
      "Epoch 8/45\n",
      "2100/2100 [==============================] - 114s 54ms/step - loss: 7.9606 - acc: 0.3626 - val_loss: 1.1002 - val_acc: 0.3542\n",
      "Epoch 9/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 1.1994 - acc: 0.3553 - val_loss: 1.0701 - val_acc: 0.3954\n",
      "Epoch 10/45\n",
      "2100/2100 [==============================] - 114s 54ms/step - loss: 2.6455 - acc: 0.3746 - val_loss: 1.1398 - val_acc: 0.3843\n",
      "Epoch 11/45\n",
      "2100/2100 [==============================] - 114s 55ms/step - loss: 1.0920 - acc: 0.4093 - val_loss: 1.0704 - val_acc: 0.4108\n",
      "Epoch 12/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 1.0615 - acc: 0.4262 - val_loss: 1.0458 - val_acc: 0.4365\n",
      "Epoch 13/45\n",
      "2100/2100 [==============================] - 114s 55ms/step - loss: 2.3280 - acc: 0.4063 - val_loss: 1.0543 - val_acc: 0.4270\n",
      "Epoch 14/45\n",
      "2100/2100 [==============================] - 114s 54ms/step - loss: 1.0614 - acc: 0.4275 - val_loss: 1.0969 - val_acc: 0.4287\n",
      "Epoch 15/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 1.0568 - acc: 0.4298 - val_loss: 1.0435 - val_acc: 0.4334\n",
      "Epoch 16/45\n",
      "2100/2100 [==============================] - 114s 54ms/step - loss: 1.0885 - acc: 0.4272 - val_loss: 1.0644 - val_acc: 0.4188\n",
      "Epoch 17/45\n",
      "2100/2100 [==============================] - 114s 54ms/step - loss: 1.0462 - acc: 0.4362 - val_loss: 1.0430 - val_acc: 0.4363\n",
      "Epoch 18/45\n",
      "2100/2100 [==============================] - 117s 56ms/step - loss: 1.1948 - acc: 0.4285 - val_loss: 1.0377 - val_acc: 0.4480\n",
      "Epoch 19/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 1.0373 - acc: 0.4428 - val_loss: 1.0364 - val_acc: 0.4527\n",
      "Epoch 20/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 1.0251 - acc: 0.4545 - val_loss: 1.0024 - val_acc: 0.4713\n",
      "Epoch 21/45\n",
      "2100/2100 [==============================] - 114s 54ms/step - loss: 1.0119 - acc: 0.4636 - val_loss: 1.0026 - val_acc: 0.4629\n",
      "Epoch 22/45\n",
      "2100/2100 [==============================] - 114s 54ms/step - loss: 0.9817 - acc: 0.4896 - val_loss: 0.9341 - val_acc: 0.5293\n",
      "Epoch 23/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.9771 - acc: 0.4942 - val_loss: 0.9373 - val_acc: 0.5168\n",
      "Epoch 24/45\n",
      "2100/2100 [==============================] - 114s 54ms/step - loss: 0.9021 - acc: 0.5552 - val_loss: 0.9752 - val_acc: 0.4880\n",
      "Epoch 25/45\n",
      "2100/2100 [==============================] - 114s 54ms/step - loss: 0.7355 - acc: 0.6521 - val_loss: 0.5980 - val_acc: 0.7219\n",
      "Epoch 26/45\n",
      "2100/2100 [==============================] - 114s 54ms/step - loss: 0.9580 - acc: 0.5133 - val_loss: 0.9847 - val_acc: 0.4880\n",
      "Epoch 27/45\n",
      "2100/2100 [==============================] - 114s 54ms/step - loss: 1.1225 - acc: 0.4807 - val_loss: 1.0086 - val_acc: 0.4656\n",
      "Epoch 28/45\n",
      "2100/2100 [==============================] - 114s 54ms/step - loss: 1.0375 - acc: 0.4792 - val_loss: 0.9942 - val_acc: 0.4897\n",
      "Epoch 29/45\n",
      "2100/2100 [==============================] - 114s 54ms/step - loss: 0.9855 - acc: 0.4910 - val_loss: 0.9546 - val_acc: 0.5214\n",
      "Epoch 30/45\n",
      "2100/2100 [==============================] - 114s 54ms/step - loss: 1.0527 - acc: 0.4887 - val_loss: 1.0401 - val_acc: 0.4428\n",
      "Epoch 31/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.9981 - acc: 0.4779 - val_loss: 0.8498 - val_acc: 0.6034\n",
      "Epoch 32/45\n",
      "2100/2100 [==============================] - 114s 54ms/step - loss: 1.1402 - acc: 0.4705 - val_loss: 0.9971 - val_acc: 0.4815\n",
      "Epoch 33/45\n",
      "2100/2100 [==============================] - 114s 54ms/step - loss: 0.9916 - acc: 0.4854 - val_loss: 0.9953 - val_acc: 0.4827\n",
      "Epoch 34/45\n",
      "2100/2100 [==============================] - 117s 56ms/step - loss: 0.9999 - acc: 0.4799 - val_loss: 0.9860 - val_acc: 0.4903\n",
      "Epoch 35/45\n",
      "2100/2100 [==============================] - 114s 54ms/step - loss: 0.9747 - acc: 0.4947 - val_loss: 1.0068 - val_acc: 0.4694\n",
      "Epoch 36/45\n",
      "2100/2100 [==============================] - 114s 54ms/step - loss: 1.0013 - acc: 0.4743 - val_loss: 0.9895 - val_acc: 0.4855\n",
      "Epoch 37/45\n",
      "2100/2100 [==============================] - 114s 54ms/step - loss: 0.9813 - acc: 0.4915 - val_loss: 0.8432 - val_acc: 0.6028\n",
      "Epoch 38/45\n",
      "2100/2100 [==============================] - 114s 54ms/step - loss: 1.1242 - acc: 0.4697 - val_loss: 0.9970 - val_acc: 0.4781\n",
      "Epoch 39/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.9884 - acc: 0.4857 - val_loss: 0.9735 - val_acc: 0.4971\n",
      "Epoch 40/45\n",
      "2100/2100 [==============================] - 116s 55ms/step - loss: 0.9583 - acc: 0.5257 - val_loss: 1.0179 - val_acc: 0.4603\n",
      "Epoch 41/45\n",
      "2100/2100 [==============================] - 114s 54ms/step - loss: 1.0075 - acc: 0.4706 - val_loss: 0.9967 - val_acc: 0.4796\n",
      "Epoch 42/45\n",
      "2100/2100 [==============================] - 114s 54ms/step - loss: 0.9884 - acc: 0.4878 - val_loss: 0.9897 - val_acc: 0.4859\n",
      "Epoch 43/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.9235 - acc: 0.5336 - val_loss: 1.0170 - val_acc: 0.4588\n",
      "Epoch 44/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.9948 - acc: 0.4793 - val_loss: 0.9799 - val_acc: 0.4942\n",
      "Epoch 45/45\n",
      "2100/2100 [==============================] - 114s 54ms/step - loss: 0.9780 - acc: 0.4946 - val_loss: 0.9641 - val_acc: 0.5112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ab82a0aa950>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 45\n",
    "batch_size = 100\n",
    "K.set_value(pfn.model.optimizer.learning_rate, 2e-4)\n",
    "\n",
    "pfn.fit(X_train, Y_train,\n",
    "        epochs=num_epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, Y_val),\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc997d7f-544e-4409-8140-9c4873fb645a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "2100/2100 [==============================] - 116s 55ms/step - loss: 0.8206 - acc: 0.6083 - val_loss: 0.6428 - val_acc: 0.7047\n",
      "Epoch 2/45\n",
      "2100/2100 [==============================] - 114s 54ms/step - loss: 0.6065 - acc: 0.7231 - val_loss: 0.5968 - val_acc: 0.7206\n",
      "Epoch 3/45\n",
      "2100/2100 [==============================] - 114s 54ms/step - loss: 0.5749 - acc: 0.7392 - val_loss: 0.5606 - val_acc: 0.7439\n",
      "Epoch 4/45\n",
      "2100/2100 [==============================] - 114s 54ms/step - loss: 0.5588 - acc: 0.7471 - val_loss: 0.5544 - val_acc: 0.7488\n",
      "Epoch 5/45\n",
      "2100/2100 [==============================] - 114s 54ms/step - loss: 0.5463 - acc: 0.7529 - val_loss: 0.5375 - val_acc: 0.7587\n",
      "Epoch 6/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.5363 - acc: 0.7573 - val_loss: 0.5542 - val_acc: 0.7480\n",
      "Epoch 7/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.9827 - acc: 0.7043 - val_loss: 0.6051 - val_acc: 0.7259\n",
      "Epoch 8/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.5662 - acc: 0.7445 - val_loss: 0.5455 - val_acc: 0.7528\n",
      "Epoch 9/45\n",
      "2100/2100 [==============================] - 114s 54ms/step - loss: 0.5332 - acc: 0.7619 - val_loss: 0.5569 - val_acc: 0.7453\n",
      "Epoch 10/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.5215 - acc: 0.7672 - val_loss: 0.5208 - val_acc: 0.7639\n",
      "Epoch 11/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.5159 - acc: 0.7705 - val_loss: 0.5382 - val_acc: 0.7570\n",
      "Epoch 12/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.5135 - acc: 0.7708 - val_loss: 0.5038 - val_acc: 0.7724\n",
      "Epoch 13/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.5112 - acc: 0.7716 - val_loss: 0.5199 - val_acc: 0.7678\n",
      "Epoch 14/45\n",
      "2100/2100 [==============================] - 114s 54ms/step - loss: 0.5114 - acc: 0.7715 - val_loss: 0.5069 - val_acc: 0.7703\n",
      "Epoch 15/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.5046 - acc: 0.7754 - val_loss: 0.4982 - val_acc: 0.7770\n",
      "Epoch 16/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.5051 - acc: 0.7748 - val_loss: 0.5032 - val_acc: 0.7742\n",
      "Epoch 17/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.4999 - acc: 0.7768 - val_loss: 0.4957 - val_acc: 0.7804\n",
      "Epoch 18/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.4965 - acc: 0.7788 - val_loss: 0.4820 - val_acc: 0.7872\n",
      "Epoch 19/45\n",
      "2100/2100 [==============================] - 114s 55ms/step - loss: 0.4932 - acc: 0.7796 - val_loss: 0.4841 - val_acc: 0.7841\n",
      "Epoch 20/45\n",
      "2100/2100 [==============================] - 114s 55ms/step - loss: 0.7110 - acc: 0.6715 - val_loss: 0.6778 - val_acc: 0.6955\n",
      "Epoch 21/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.5936 - acc: 0.7303 - val_loss: 0.5836 - val_acc: 0.7323\n",
      "Epoch 22/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.5443 - acc: 0.7529 - val_loss: 0.5390 - val_acc: 0.7526\n",
      "Epoch 23/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.5275 - acc: 0.7626 - val_loss: 0.5254 - val_acc: 0.7649\n",
      "Epoch 24/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.5216 - acc: 0.7651 - val_loss: 0.5316 - val_acc: 0.7571\n",
      "Epoch 25/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.5134 - acc: 0.7702 - val_loss: 0.5244 - val_acc: 0.7631\n",
      "Epoch 26/45\n",
      "2100/2100 [==============================] - 114s 55ms/step - loss: 0.5067 - acc: 0.7739 - val_loss: 0.4988 - val_acc: 0.7763\n",
      "Epoch 27/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.5020 - acc: 0.7759 - val_loss: 0.5314 - val_acc: 0.7575\n",
      "Epoch 28/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.7271 - acc: 0.6616 - val_loss: 0.6683 - val_acc: 0.6935\n",
      "Epoch 29/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.5700 - acc: 0.7427 - val_loss: 0.5452 - val_acc: 0.7510\n",
      "Epoch 30/45\n",
      "2100/2100 [==============================] - 114s 55ms/step - loss: 0.5251 - acc: 0.7644 - val_loss: 0.5113 - val_acc: 0.7706\n",
      "Epoch 31/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.5101 - acc: 0.7732 - val_loss: 0.5118 - val_acc: 0.7677\n",
      "Epoch 32/45\n",
      "2100/2100 [==============================] - 114s 55ms/step - loss: 0.5004 - acc: 0.7775 - val_loss: 0.5082 - val_acc: 0.7717\n",
      "Epoch 33/45\n",
      "2100/2100 [==============================] - 114s 54ms/step - loss: 0.4931 - acc: 0.7809 - val_loss: 0.4964 - val_acc: 0.7789\n",
      "Epoch 34/45\n",
      "2100/2100 [==============================] - 114s 55ms/step - loss: 0.4866 - acc: 0.7833 - val_loss: 0.4929 - val_acc: 0.7804\n",
      "Epoch 35/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.4806 - acc: 0.7876 - val_loss: 0.4832 - val_acc: 0.7856\n",
      "Epoch 36/45\n",
      "2100/2100 [==============================] - 114s 55ms/step - loss: 0.4852 - acc: 0.7858 - val_loss: 0.5464 - val_acc: 0.7486\n",
      "Epoch 37/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.4728 - acc: 0.7914 - val_loss: 0.4751 - val_acc: 0.7913\n",
      "Epoch 38/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.4696 - acc: 0.7926 - val_loss: 0.4639 - val_acc: 0.7969\n",
      "Epoch 39/45\n",
      "2100/2100 [==============================] - 114s 55ms/step - loss: 0.6836 - acc: 0.6814 - val_loss: 0.9049 - val_acc: 0.5606\n",
      "Epoch 40/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.8252 - acc: 0.6096 - val_loss: 0.6371 - val_acc: 0.7046\n",
      "Epoch 41/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.5704 - acc: 0.7389 - val_loss: 0.5384 - val_acc: 0.7567\n",
      "Epoch 42/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.5300 - acc: 0.7604 - val_loss: 0.5871 - val_acc: 0.7284\n",
      "Epoch 43/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.5154 - acc: 0.7683 - val_loss: 0.4970 - val_acc: 0.7803\n",
      "Epoch 44/45\n",
      "2100/2100 [==============================] - 114s 54ms/step - loss: 0.5034 - acc: 0.7744 - val_loss: 0.5180 - val_acc: 0.7682\n",
      "Epoch 45/45\n",
      "2100/2100 [==============================] - 114s 54ms/step - loss: 0.4958 - acc: 0.7784 - val_loss: 0.4886 - val_acc: 0.7820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ab82acc1d20>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 45\n",
    "batch_size = 100\n",
    "K.set_value(pfn.model.optimizer.learning_rate, 2e-5)\n",
    "\n",
    "pfn.fit(X_train, Y_train,\n",
    "        epochs=num_epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, Y_val),\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ed643d6-66bf-495a-848e-4082db63a53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "2100/2100 [==============================] - 116s 55ms/step - loss: 0.4879 - acc: 0.7821 - val_loss: 0.4964 - val_acc: 0.7779\n",
      "Epoch 2/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.4808 - acc: 0.7860 - val_loss: 0.4754 - val_acc: 0.7913\n",
      "Epoch 3/45\n",
      "2100/2100 [==============================] - 114s 55ms/step - loss: 0.4753 - acc: 0.7894 - val_loss: 0.4732 - val_acc: 0.7889\n",
      "Epoch 4/45\n",
      "2100/2100 [==============================] - 114s 55ms/step - loss: 0.4734 - acc: 0.7901 - val_loss: 0.4834 - val_acc: 0.7862\n",
      "Epoch 5/45\n",
      "2100/2100 [==============================] - 114s 55ms/step - loss: 0.4692 - acc: 0.7931 - val_loss: 0.4587 - val_acc: 0.7981\n",
      "Epoch 6/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.4667 - acc: 0.7940 - val_loss: 0.4597 - val_acc: 0.7982\n",
      "Epoch 7/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.4594 - acc: 0.7971 - val_loss: 0.4687 - val_acc: 0.7939\n",
      "Epoch 8/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.4572 - acc: 0.7990 - val_loss: 0.4798 - val_acc: 0.7862\n",
      "Epoch 9/45\n",
      "2100/2100 [==============================] - 114s 55ms/step - loss: 0.4535 - acc: 0.8009 - val_loss: 0.4568 - val_acc: 0.8020\n",
      "Epoch 10/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.4520 - acc: 0.8008 - val_loss: 0.4579 - val_acc: 0.7978\n",
      "Epoch 11/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.4486 - acc: 0.8032 - val_loss: 0.4698 - val_acc: 0.7887\n",
      "Epoch 12/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.4457 - acc: 0.8047 - val_loss: 0.4497 - val_acc: 0.8052\n",
      "Epoch 13/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.4431 - acc: 0.8051 - val_loss: 0.4477 - val_acc: 0.8044\n",
      "Epoch 14/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.4414 - acc: 0.8061 - val_loss: 0.4640 - val_acc: 0.7974\n",
      "Epoch 15/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.4401 - acc: 0.8065 - val_loss: 0.4540 - val_acc: 0.8000\n",
      "Epoch 16/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.4365 - acc: 0.8087 - val_loss: 0.4525 - val_acc: 0.7986\n",
      "Epoch 17/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.4347 - acc: 0.8092 - val_loss: 0.4417 - val_acc: 0.8092\n",
      "Epoch 18/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.4323 - acc: 0.8102 - val_loss: 0.4617 - val_acc: 0.7986\n",
      "Epoch 19/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.4289 - acc: 0.8124 - val_loss: 0.4244 - val_acc: 0.8188\n",
      "Epoch 20/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.4280 - acc: 0.8131 - val_loss: 0.4367 - val_acc: 0.8087\n",
      "Epoch 21/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.4253 - acc: 0.8132 - val_loss: 0.4523 - val_acc: 0.8020\n",
      "Epoch 22/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.4248 - acc: 0.8144 - val_loss: 0.4286 - val_acc: 0.8127\n",
      "Epoch 23/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.4203 - acc: 0.8162 - val_loss: 0.4275 - val_acc: 0.8140\n",
      "Epoch 24/45\n",
      "2100/2100 [==============================] - 114s 55ms/step - loss: 0.4234 - acc: 0.8149 - val_loss: 0.4235 - val_acc: 0.8155\n",
      "Epoch 25/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.4167 - acc: 0.8182 - val_loss: 0.4478 - val_acc: 0.8030\n",
      "Epoch 26/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.4183 - acc: 0.8169 - val_loss: 0.4222 - val_acc: 0.8165\n",
      "Epoch 27/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.4165 - acc: 0.8190 - val_loss: 0.4327 - val_acc: 0.8101\n",
      "Epoch 28/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.4142 - acc: 0.8198 - val_loss: 0.4430 - val_acc: 0.8041\n",
      "Epoch 29/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.4091 - acc: 0.8222 - val_loss: 0.4275 - val_acc: 0.8135\n",
      "Epoch 30/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.4100 - acc: 0.8225 - val_loss: 0.4154 - val_acc: 0.8218\n",
      "Epoch 31/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.4097 - acc: 0.8212 - val_loss: 0.4462 - val_acc: 0.8017\n",
      "Epoch 32/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.4036 - acc: 0.8246 - val_loss: 0.4171 - val_acc: 0.8179\n",
      "Epoch 33/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.4048 - acc: 0.8247 - val_loss: 0.4133 - val_acc: 0.8232\n",
      "Epoch 34/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.3995 - acc: 0.8269 - val_loss: 0.4339 - val_acc: 0.8108\n",
      "Epoch 35/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.4006 - acc: 0.8269 - val_loss: 0.4233 - val_acc: 0.8131\n",
      "Epoch 36/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.3994 - acc: 0.8271 - val_loss: 0.4107 - val_acc: 0.8229\n",
      "Epoch 37/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.3975 - acc: 0.8280 - val_loss: 0.4191 - val_acc: 0.8168\n",
      "Epoch 38/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.3950 - acc: 0.8286 - val_loss: 0.4057 - val_acc: 0.8230\n",
      "Epoch 39/45\n",
      "2100/2100 [==============================] - 116s 55ms/step - loss: 0.3922 - acc: 0.8310 - val_loss: 0.4082 - val_acc: 0.8253\n",
      "Epoch 40/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.3928 - acc: 0.8304 - val_loss: 0.3953 - val_acc: 0.8298\n",
      "Epoch 41/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.3914 - acc: 0.8314 - val_loss: 0.4074 - val_acc: 0.8240\n",
      "Epoch 42/45\n",
      "2100/2100 [==============================] - 115s 55ms/step - loss: 0.4163 - acc: 0.8202 - val_loss: 0.4045 - val_acc: 0.8253\n",
      "Epoch 43/45\n",
      "2100/2100 [==============================] - 114s 55ms/step - loss: 0.4415 - acc: 0.8089 - val_loss: 0.7706 - val_acc: 0.6489\n",
      "Epoch 44/45\n",
      "2100/2100 [==============================] - 114s 54ms/step - loss: 0.4565 - acc: 0.7996 - val_loss: 0.4075 - val_acc: 0.8250\n",
      "Epoch 45/45\n",
      "2100/2100 [==============================] - 114s 55ms/step - loss: 0.3842 - acc: 0.8344 - val_loss: 0.4330 - val_acc: 0.8085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ab82ad6b100>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 45\n",
    "batch_size = 100\n",
    "K.set_value(pfn.model.optimizer.learning_rate, 2e-5)\n",
    "\n",
    "pfn.fit(X_train, Y_train,\n",
    "        epochs=num_epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, Y_val),\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f8f3573-c9db-40bf-8333-5a7ac55d0366",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/usatlas/atlas01/atlasdisk/users/atlas_wifeng/photon-jet/models/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_pfn_lib\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "pfn.save(f\"/usatlas/atlas01/atlasdisk/users/atlas_wifeng/photon-jet/models/{task_name}_pfn_lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aba914-ace5-4981-983e-63e8655efd14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "top-tagging",
   "language": "python",
   "name": "top-tagging"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12345a37-d28b-4d50-8b67-32a9052625e9",
   "metadata": {},
   "source": [
    "# CNN test 1\n",
    "\n",
    "Ok let's train a CNN on this thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "058ab6b9-e4e1-434a-a5fc-08fd610a0137",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import h5py\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "from matplotlib import pyplot as plt\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cf2ca5b-792c-4f7f-9598-608baf4880c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Utility functions and whatnot\n",
    "def convert_size(size_bytes):\n",
    "    if size_bytes == 0:\n",
    "        return \"0B\"\n",
    "    size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
    "    i = int(math.floor(math.log(size_bytes, 1024)))\n",
    "    p = math.pow(1024, i)\n",
    "    s = round(size_bytes / p, 2)\n",
    "    return \"%s %s\" % (s, size_name[i])\n",
    "\n",
    "\n",
    "class_labels = [\"pion\", \"photon\", \"scalar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14e9e9e5-d5b2-4b9b-bee1-c5f91246764f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/usatlas/atlas01/atlasdisk/users/atlas_wifeng/photon-jet/data/processed/scalar_test\"\n",
    "os.chdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "462ff3c9-9e66-4f45-b51f-a912fdbccf97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_0    float64         (300000, 4, 16)      146.48 MB\n",
      "layer_1    float64         (300000, 4, 128)     1.14 GB\n",
      "layer_2    float64         (300000, 16, 16)     585.94 MB\n",
      "layer_3    float64         (300000, 16, 8)      292.97 MB\n",
      "energy     float64         (300000, 1)          2.29 MB\n",
      "overflow   float64         (300000, 4)          9.16 MB\n",
      "label      int64           (300000,)            2.29 MB\n"
     ]
    }
   ],
   "source": [
    "# Grab the data\n",
    "all_jets = np.load(\"all_jets.npz\")\n",
    "\n",
    "for layer, arr in all_jets.items():\n",
    "    print(\n",
    "        layer.ljust(10),\n",
    "        str(arr.dtype).ljust(15),\n",
    "        str(arr.shape).ljust(20),\n",
    "        convert_size(arr.nbytes)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f05f91-1fa8-4785-8ff1-73847b258c26",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Visualize some data\n",
    "\n",
    "Just to see what jets look like. Utility functions defined here:\n",
    "- `nth_jet(n)`: displays the `n`th jet from `all_jets`\n",
    "- `graph_jet(jet)`: graphs a jet (a dict with `energy`, `layer_0`, ..., `label` keys)\n",
    "\n",
    "TODO: add together stuff for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc53d19-7d15-4eb6-8beb-fde771d657ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def nth_jet(n):\n",
    "    jet = {}\n",
    "    for layer in all_jets.keys():\n",
    "        jet[layer] = all_jets[layer][n]\n",
    "    return jet\n",
    "\n",
    "def graph_jet(jet):\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(20, 4))\n",
    "    for layer, ax in zip([\"layer_0\", \"layer_1\", \"layer_2\", \"layer_3\"], axs):\n",
    "        im = ax.imshow(\n",
    "            jet[layer].T,\n",
    "            interpolation='none',\n",
    "            cmap=\"viridis\",\n",
    "            extent=[-0.2, 0.2, -0.02, 0.02],\n",
    "            aspect=10\n",
    "        )\n",
    "        ax.set_title(layer)\n",
    "        \n",
    "    fig.suptitle(class_labels[jet['label']])\n",
    "    fig.colorbar(im, ax=axs.ravel().tolist())\n",
    "    \n",
    "    print(f\"Layers for {class_labels[jet['label']]} (class {jet['label']})\")\n",
    "    plt.show()\n",
    "    if \"energy\" in jet: print(f\"energy:   {jet['energy']}\")\n",
    "    if \"overflow\" in jet: print(f\"overflow: {jet['overflow']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b8f147-fd65-4672-ab36-2631df0d6971",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_idxs = [None] * 3\n",
    "i = 0\n",
    "while True:\n",
    "    label = all_jets[\"label\"][i]\n",
    "    if example_idxs[label] == None:\n",
    "        example_idxs[label] = i\n",
    "    if all(x != None for x in example_idxs):\n",
    "        break\n",
    "    i += 1\n",
    "    \n",
    "for i in example_idxs:\n",
    "    graph_jet(nth_jet(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7bdf80-1f37-478c-ab47-f3f63e0b132d",
   "metadata": {},
   "source": [
    "### Graph \"average jet\" for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda3ddd2-3cbe-4132-bad9-1d2e2e341c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_average_class(label):\n",
    "    avgs = {}\n",
    "    for layer in [\"layer_0\", \"layer_1\", \"layer_2\", \"layer_3\"]:\n",
    "        print(f\"Processing {layer}\")\n",
    "        arr = all_jets[layer][all_jets[\"label\"] == label]\n",
    "        avgs[layer] = arr.mean(axis=0)\n",
    "\n",
    "    avgs[\"label\"] = label\n",
    "    graph_jet(avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f9a882-f8d6-419b-984c-d6701c9c04d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    graph_average_class(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7bffcc-4811-41b4-932b-47f78a8b847c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Split into train/dev/test\n",
    "\n",
    "After this, we have three sets of jets:\n",
    "- `jets_train` (210k)\n",
    "- `jets_dev` (45k)\n",
    "- `jets_test` (45k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f00908bf-feb0-4fc8-b62e-8a9bd5154f72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting layer layer_0...\n",
      "Splitting layer layer_1...\n",
      "Splitting layer layer_2...\n",
      "Splitting layer layer_3...\n",
      "Splitting layer energy...\n",
      "Splitting layer overflow...\n",
      "Splitting layer label...\n"
     ]
    }
   ],
   "source": [
    "m = len(all_jets[\"label\"])\n",
    "\n",
    "f_train, f_dev, f_test = 0.7, 0.15, 0.15\n",
    "n_train, n_dev, n_test = map(lambda x: int(m * x), (f_train, f_dev, f_test))\n",
    "\n",
    "jets_train = {}\n",
    "jets_dev = {}\n",
    "jets_test = {}\n",
    "\n",
    "for layer in all_jets.keys():\n",
    "    print(f\"Splitting layer {layer}...\")\n",
    "    jets_train[layer] = all_jets[layer][:n_train]\n",
    "    jets_dev[layer] = all_jets[layer][n_train:(n_train + n_dev)]\n",
    "    jets_test[layer] = all_jets[layer][(n_train + n_dev):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b9c36aa-a76a-4256-8036-90bdd45f85ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_train: 210000 (1.51 GB)\n",
      "n_dev: 45000 (331.65 MB)\n",
      "n_test: 45000 (331.65 MB)\n"
     ]
    }
   ],
   "source": [
    "def total_size(jets):\n",
    "    res = 0\n",
    "    for layer in jets:\n",
    "        res += jets[layer].nbytes\n",
    "    return convert_size(res)\n",
    "\n",
    "print(f\"n_train: {n_train} ({total_size(jets_train)})\")\n",
    "print(f\"n_dev: {n_dev} ({total_size(jets_dev)})\")\n",
    "print(f\"n_test: {n_test} ({total_size(jets_test)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3d4c8d-7e79-492d-ac3c-a8d75d8a1332",
   "metadata": {},
   "source": [
    "## Create the model\n",
    "\n",
    "Simple CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dea43a6b-c440-4069-9f9f-2d791618514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import Resize, InterpolationMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44fcd683-5c99-4c4e-98b9-4fb2822279a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_0              (300000, 4, 16)\n",
      "layer_1              (300000, 4, 128)\n",
      "layer_2              (300000, 16, 16)\n",
      "layer_3              (300000, 16, 8)\n",
      "energy               (300000, 1)\n",
      "overflow             (300000, 4)\n",
      "label                (300000,)\n"
     ]
    }
   ],
   "source": [
    "for layer in all_jets.keys():\n",
    "    print(layer.ljust(20), all_jets[layer].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9ddd60c5-cc7d-4514-a13d-09b242d186d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        \n",
    "        # Things for upsampling\n",
    "        # \"l0_tc\" is \"layer_0 transpose convolution\"\n",
    "        # https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html\n",
    "        \n",
    "        self.resize = Resize(size=(32, 32), interpolation=InterpolationMode.NEAREST, antialias=False)\n",
    "        \n",
    "        # Let's use LeNet: https://en.wikipedia.org/wiki/LeNet#/media/File:Comparison_image_neural_networks.svg\n",
    "        channel_sizes = [10, 20]\n",
    "        \n",
    "        self.cnn1 = torch.nn.Conv2d(in_channels=4, out_channels=channel_sizes[0], kernel_size=5, stride=1, padding=2)\n",
    "        self.maxpool1 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.maxpool1_bn = torch.nn.BatchNorm2d(channel_sizes[0])\n",
    "\n",
    "        self.cnn2 = torch.nn.Conv2d(in_channels=channel_sizes[0], out_channels=channel_sizes[1], kernel_size=5, stride=1, padding=2)\n",
    "        self.maxpool2 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.maxpool2_bn = torch.nn.BatchNorm2d(channel_sizes[1])\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(channel_sizes[1] * 8 * 8 + 5, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        relu = torch.nn.functional.relu\n",
    "        \n",
    "        layer0 = self.resize(x[\"layer_0\"])\n",
    "        layer1 = self.resize(x[\"layer_1\"])\n",
    "        layer2 = self.resize(x[\"layer_2\"])\n",
    "        layer3 = self.resize(x[\"layer_3\"])\n",
    "        \n",
    "        img = torch.stack([layer0, layer1, layer2, layer3], dim=1)\n",
    "\n",
    "        conv1_out = relu(self.cnn1(img))\n",
    "        pool1_out = self.maxpool1(conv1_out)\n",
    "        pool1_out_bn = self.maxpool1_bn(pool1_out)\n",
    "\n",
    "        conv2_out = relu(self.cnn2(pool1_out_bn))\n",
    "        pool2_out = self.maxpool2(conv2_out)\n",
    "        pool2_out_bn = self.maxpool2_bn(pool2_out)\n",
    "\n",
    "        fcn_input = pool2_out.view(pool2_out_bn.size(0), -1)        \n",
    "        fcn_input = torch.cat((fcn_input, x[\"energy\"], x[\"overflow\"]), dim=1)\n",
    "        fc1_out = self.fc1(fcn_input)\n",
    "\n",
    "        return fc1_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057846d0-b0e3-4a88-9bee-bf5900f4226e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Select hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "abe496b9-fdb6-49d6-8f56-405be8f942e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(55)\n",
    "\n",
    "model = CNNModel()\n",
    "\n",
    "learning_rate = 1e-3\n",
    "epochs = 10\n",
    "batchsize = 500\n",
    "\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.to(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fe1fd4db-6a0a-45c1-91be-e012340f4559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allocated: 1.69 GB\n",
      "reserved: 1.76 GB\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(\"allocated:\", convert_size(torch.cuda.memory_allocated()))\n",
    "print(\"reserved:\", convert_size(torch.cuda.memory_reserved()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5c0e34-775b-4cbd-a24f-41303187b4f3",
   "metadata": {},
   "source": [
    "### Begin training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7048a870-bb4f-400a-a1e4-ce805a9f1bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholders for training loss and dev accuracy during training\n",
    "# Training loss should be tracked for each iteration (1 iteration -> single forward pass to the network)\n",
    "# dev accuracy should be evaluated every 'Epoch' (1 epoch -> full training dataset)\n",
    "# If using batch gradient, 1 iteration = 1 epoch\n",
    "\n",
    "train_loss_list = []\n",
    "train_accuracy_list = []\n",
    "dev_accuracy_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3700b0b7-69fb-4f49-ac79-71f6f25952e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_torch(jets):\n",
    "    res = {}\n",
    "    for key in jets:\n",
    "        res[key] = torch.from_numpy(jets[key])\n",
    "        if np.issubdtype(jets[key].dtype, float):\n",
    "            res[key] = res[key].float().to(0)\n",
    "        elif np.issubdtype(jets[key].dtype, int):\n",
    "            res[key] = res[key].long().to(0)\n",
    "    return res\n",
    "\n",
    "def split_batches(jets, batchsize):\n",
    "    m = len(jets[\"label\"])\n",
    "    n_batches = m // batchsize\n",
    "    \n",
    "    d_wise = {}\n",
    "    for key in jets:\n",
    "        d_wise[key] = np.array_split(jets[key], n_batches)\n",
    "        \n",
    "    batches = []\n",
    "    for i in range(n_batches):\n",
    "        batches.append({key: d_wise[key][i] for key in d_wise})\n",
    "    \n",
    "    return batches\n",
    "\n",
    "torch_dev = to_torch(jets_dev)\n",
    "train_batched = split_batches(to_torch(jets_train), batchsize)\n",
    "\n",
    "batch_split_num = len(train_batched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b9fcbe3b-3d3b-4be9-8873-64ed6acab776",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 420/420 [00:03<00:00, 123.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, tl=1.09217, ta=0.33321, da=0.33176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 420/420 [00:03<00:00, 123.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, tl=1.09259, ta=0.3304 , da=0.3242 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 420/420 [00:03<00:00, 122.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, tl=1.0924 , ta=0.33199, da=0.33133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 420/420 [00:03<00:00, 123.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, tl=1.09142, ta=0.33162, da=0.33116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 420/420 [00:03<00:00, 123.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, tl=1.09204, ta=0.33201, da=0.33104\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    correct = 0\n",
    "    \n",
    "    for b in tqdm(range(batch_split_num)):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(train_batched[b])\n",
    "        loss = loss_func(outputs, train_batched[b][\"label\"])        \n",
    "        loss.backward() # Compute gradients        \n",
    "        \n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        correct += torch.sum((predictions == train_batched[b][\"label\"]).type(torch.FloatTensor))\n",
    "        \n",
    "        train_loss_list.append(loss.item())\n",
    "\n",
    "        optimizer.step() # Update parameters\n",
    "        \n",
    "    train_accuracy_list.append((correct / len(jets_train[\"label\"])).item())\n",
    "        \n",
    "    # Compute dev accuracy\n",
    "    with torch.no_grad():\n",
    "        predictions = torch.argmax(model(torch_dev), dim=1)\n",
    "        correct = predictions == torch_dev[\"label\"]\n",
    "        accuracy = torch.mean(correct.type(torch.FloatTensor))\n",
    "        dev_accuracy_list.append(accuracy.item())        \n",
    "    \n",
    "    # Print a report\n",
    "    tl = str(round(train_loss_list[-1], 5)).ljust(7)      # Training loss\n",
    "    ta = str(round(train_accuracy_list[-1], 5)).ljust(7)  # Training accuracy\n",
    "    da = str(round(dev_accuracy_list[-1], 5)).ljust(7)    # Dev accuracy\n",
    "    desc = f\"Epoch {epoch}, tl={tl}, ta={ta}, da={da}\"\n",
    "    \n",
    "    #pbar.set_description(desc)\n",
    "    print(desc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "top-tagging",
   "language": "python",
   "name": "top-tagging"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c8b613d-e95f-43c1-93b8-6646e0be5f54",
   "metadata": {},
   "source": [
    "# Particle Flow Test 1\n",
    "\n",
    "Make our own particle flow network, train it on top tagging dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b2625fc-9815-410c-a9a6-e636c6c07a5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Up to a minute to import everything\n",
    "# Make tensorflow quieter\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "# Computing imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "# Useful imports\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Energyflow imports\n",
    "import energyflow as ef\n",
    "from energyflow.utils import data_split, to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b4b857-0f8d-484b-81d0-2183374b56e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import, preprocess data\n",
    "\n",
    "Data lives in `X_train`, `X_val`, `X_test`, and `Y_train`, `Y_val`, `Y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5acb3473-0268-4a28-96d5-b84c3a1a7ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data\n"
     ]
    }
   ],
   "source": [
    "# ~5 sec\n",
    "jets_path = \"/usatlas/atlas01/atlasdisk/users/atlas_wifeng/photon-jet/data/processed/scalar_test/all_jets_point_cloud.npz\"\n",
    "jets = np.load(jets_path)\n",
    "\n",
    "X, y = jets[\"X\"], jets[\"y\"]\n",
    "Y = to_categorical(y)\n",
    "\n",
    "print(\"Loaded data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b9a5fb0-9665-4758-9d2a-bdfe1eb6ec7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done train/val/test split\n"
     ]
    }
   ],
   "source": [
    "# ~5 sec\n",
    "# Do train/val/test split\n",
    "n_val = 20000\n",
    "n_test = 20000\n",
    "\n",
    "(X_train, X_val, X_test,\n",
    " Y_train, Y_val, Y_test) = data_split(X, Y, val=n_val, test=n_test)\n",
    "\n",
    "print(\"Done train/val/test split\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ab3922-436a-41c0-bd40-83c4e4d5ad06",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df8f8ff-7dca-400f-b136-e8b99914ab03",
   "metadata": {},
   "source": [
    "PFN model:\n",
    "$$\\text{PFN}=F\\left(\\sum_{i=1}^M \\Phi(p_i)\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2018c05c-4e0d-4a4f-a80f-f26a5caa6515",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def PFN(n_features,\n",
    "        n_particles,\n",
    "        n_outputs,\n",
    "        Phi_sizes,\n",
    "        F_sizes,\n",
    "        name=None):\n",
    "    \n",
    "        inputs = layers.Input((n_particles, n_features), name=\"input\")    \n",
    "        masking_layer = layers.Masking(\n",
    "            mask_value=0.,\n",
    "            input_shape=(n_particles, n_features)\n",
    "        )\n",
    "        Phi_layers = [layers.Dense(size, activation=\"relu\", name=f\"Phi_{i}\") for i, size in enumerate(Phi_sizes)]\n",
    "        F_layers = [layers.Dense(size, activation=\"relu\", name=f\"F_{i}\") for i, size in enumerate(F_sizes)]\n",
    "        last_layer = layers.Dense(n_outputs, name=\"output\")\n",
    "        \n",
    "        x = masking_layer(inputs)\n",
    "        for layer in Phi_layers:\n",
    "            x = layers.TimeDistributed(layer)(x)\n",
    "        x = tf.math.reduce_sum(x, axis=1)\n",
    "        for layer in F_layers:\n",
    "            x = layer(x)\n",
    "        x = last_layer(x)\n",
    "        \n",
    "        return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad97813-563f-4004-8870-efe774e60fcf",
   "metadata": {},
   "source": [
    "## Compile and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e684b2cb-ce18-4876-a29b-4fe178659d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes about 5 sec the first time\n",
    "# Training hyperparameters\n",
    "lr = 1e-3\n",
    "epochs = 5\n",
    "batch_size = 10\n",
    "\n",
    "# Data dimensions\n",
    "n_features = 4\n",
    "n_particles = 960\n",
    "\n",
    "model = PFN(\n",
    "    n_features=n_features,\n",
    "    n_particles=n_particles,\n",
    "    n_outputs=3,\n",
    "    Phi_sizes=[100, 100, 50],\n",
    "    F_sizes=[100, 100, 50]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3740305-7324-4aa9-a75d-130c900055d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'current': 3997039104, 'peak': 3997118208}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.config.experimental.get_memory_info(\"GPU:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64d6615b-ccde-496b-924f-f005075d9185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 960, 4)]          0         \n",
      "                                                                 \n",
      " masking (Masking)           (None, 960, 4)            0         \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 960, 100)         500       \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 960, 100)         10100     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 960, 50)          5050      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " tf.math.reduce_sum (TFOpLam  (None, 50)               0         \n",
      " bda)                                                            \n",
      "                                                                 \n",
      " F_0 (Dense)                 (None, 100)               5100      \n",
      "                                                                 \n",
      " F_1 (Dense)                 (None, 100)               10100     \n",
      "                                                                 \n",
      " F_2 (Dense)                 (None, 50)                5050      \n",
      "                                                                 \n",
      " output (Dense)              (None, 3)                 153       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36,053\n",
      "Trainable params: 36,053\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b465b5af-c447-4c40-a90b-35f83ed0140c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49f8749-b841-425e-9d08-e1cc86c3f046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "520/520 [==============================] - 25s 41ms/step - loss: 74.8423 - accuracy: 0.3335 - val_loss: 8.7856 - val_accuracy: 0.3293\n",
      "Epoch 2/5\n",
      "520/520 [==============================] - 20s 39ms/step - loss: 16.7837 - accuracy: 0.3338 - val_loss: 1.2832 - val_accuracy: 0.3325\n",
      "Epoch 3/5\n",
      "520/520 [==============================] - 20s 39ms/step - loss: 1.2182 - accuracy: 0.3431 - val_loss: 1.1221 - val_accuracy: 0.3326\n",
      "Epoch 4/5\n",
      "520/520 [==============================] - 20s 39ms/step - loss: 1.0829 - accuracy: 0.4048 - val_loss: 1.0393 - val_accuracy: 0.4593\n",
      "Epoch 5/5\n",
      "520/520 [==============================] - 20s 39ms/step - loss: 1.0453 - accuracy: 0.4394 - val_loss: 1.0762 - val_accuracy: 0.4460\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train,\n",
    "                    epochs=1,\n",
    "                    batch_size=500,\n",
    "                    validation_data=(X_val, Y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0df962f-54b6-4971-827c-ee3cc7b04d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e8e442-467b-40e6-a690-27b95f2830ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions on test data\n",
    "preds = model.predict(X_test, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b728b3-85be-4e41-bc53-54fd398fd828",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.argmax(Y_test, axis=1)\n",
    "pred_labels = np.argmax(preds, axis=1)\n",
    "\n",
    "mask = (test_labels == pred_labels).astype(float)\n",
    "print(mask)\n",
    "print(f\"Test accuracy: {mask.mean()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "top-tagging",
   "language": "python",
   "name": "top-tagging"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

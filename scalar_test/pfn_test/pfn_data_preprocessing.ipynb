{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6860792-75db-42ca-ae56-2851fa879f84",
   "metadata": {},
   "source": [
    "# Particle flow network data preprocessing\n",
    "\n",
    "For photon jet task. Goal is to turn all the images into point clouds.\n",
    "\n",
    "May 13: Just do all 960 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42265656-4ecd-40e0-91d3-2f7301143d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import h5py\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "from matplotlib import pyplot as plt\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "775ccf76-66a2-4c19-aecf-637e4f32b685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions and whatnot\n",
    "def convert_size(size_bytes):\n",
    "    if size_bytes == 0:\n",
    "        return \"0B\"\n",
    "    size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
    "    i = int(math.floor(math.log(size_bytes, 1024)))\n",
    "    p = math.pow(1024, i)\n",
    "    s = round(size_bytes / p, 2)\n",
    "    return \"%s %s\" % (s, size_name[i])\n",
    "\n",
    "\n",
    "class_labels = [\"pion\", \"photon\", \"scalar\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58df2db2-ac03-48c8-88e2-3681713e8c65",
   "metadata": {},
   "source": [
    "## Grab data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31cb1ef0-824b-412b-b961-266b6887b661",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/usatlas/atlas01/atlasdisk/users/atlas_wifeng/photon-jet/data/processed/scalar_test\"\n",
    "os.chdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98c0883d-ed26-4543-96bf-43432f1f8a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~5 sec\n",
    "raw_pions = dict(np.load(\"pi0_40-250GeV_100k.npz\"))\n",
    "raw_photons = dict(np.load(\"gamma_40-250GeV_100k.npz\"))\n",
    "raw_scalars = dict(np.load(\"scalar1_40-250GeV_100k.npz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e152e427-22a6-44cf-bd7c-56bacf3303a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def norm_coords(n):\n",
    "    \"\"\"\n",
    "    Generate list of n consecutive numbers, normally distributed.\n",
    "        e.g. norm_coords(4) -> [-1.34, -0.45, 0.45, 1.34]\n",
    "    \"\"\"\n",
    "    x = np.arange(n)\n",
    "    return (x - np.mean(x)) / np.std(x)\n",
    "\n",
    "def to_cloud(arr, tag):\n",
    "    \"\"\"\n",
    "    Turn arr of shape (samples, rows, cols) into point clouds.\n",
    "    Point cloud looks like (samples, points, features).\n",
    "    Features will be a 7-vector of (eta, phi, energy, isLayer0, isLayer1, isLayer2, isLayer3, isLayer4).\n",
    "    \n",
    "    Points may be ragged; they will be padded in that case.\n",
    "    \"\"\"\n",
    "    n_samples, n_rows, n_cols = arr.shape\n",
    "    img_shape = (n_rows, n_cols)\n",
    "    n_points = n_rows * n_cols\n",
    "    \n",
    "    # This shape rebroadcast can take a bit to wrap your head around\n",
    "    row_coords = np.broadcast_to(norm_coords(n_rows)[:, None], img_shape)\n",
    "    col_coords = np.broadcast_to(norm_coords(n_cols)[None, :], img_shape)\n",
    "    \n",
    "    coords = np.stack((row_coords, col_coords), axis=2).reshape((n_points, -1))\n",
    "    coords = np.expand_dims(coords, axis=0)\n",
    "    # coords has shape (n_rows, n_cols)\n",
    "    \n",
    "    coords = np.broadcast_to(coords, (n_samples, n_points, 2))\n",
    "    new_arr = np.expand_dims(np.reshape(arr, (n_samples, -1)), axis=2)\n",
    "    \n",
    "    tag_arr = np.zeros((n_samples, n_points, 4))\n",
    "    tag_arr[:, :, tag] = 1\n",
    "    \n",
    "    return np.concatenate((coords, new_arr, tag_arr), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89d6378d-9886-48bd-be12-77249aca2acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(dataset):\n",
    "    res = []\n",
    "    layers = [f\"layer_{i}\" for i in range(4)]\n",
    "    \n",
    "    for i, layer in enumerate(layers):\n",
    "        print(f\"Processing {layer}...\")\n",
    "        res.append(to_cloud(dataset[layer], tag=i))\n",
    "        \n",
    "    return np.concatenate(res, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "965e3a31-fce7-4cd5-bf09-a59f3fd87ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layer_0...\n",
      "Processing layer_1...\n",
      "Processing layer_2...\n",
      "Processing layer_3...\n",
      "Processing layer_0...\n",
      "Processing layer_1...\n",
      "Processing layer_2...\n",
      "Processing layer_3...\n",
      "Processing layer_0...\n",
      "Processing layer_1...\n",
      "Processing layer_2...\n",
      "Processing layer_3...\n"
     ]
    }
   ],
   "source": [
    "point_pions = process_dataset(raw_pions)\n",
    "point_photons = process_dataset(raw_photons)\n",
    "point_scalars = process_dataset(raw_scalars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4203163e-83b8-49dd-ae08-7fbc29c3fec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100000\n",
    "\n",
    "all_jets = np.concatenate([point_pions, point_photons, point_scalars], axis=0)\n",
    "labels = np.array((0,) * N + (1,) * N + (2,) * N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dbe44e75-9aad-4b69-bb28-c9b5e8ceaf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(labels) == len(all_jets))\n",
    "order = np.random.permutation(len(labels))\n",
    "\n",
    "all_jets = all_jets[order]\n",
    "labels = labels[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e838b168-1496-4007-8fcd-e34c4eb6b54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All jets take up 15.02 GB\n"
     ]
    }
   ],
   "source": [
    "print(f\"All jets take up {convert_size(all_jets.nbytes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f274c260-a360-41d2-98a3-f329b6edb5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~10 sec\n",
    "np.savez(f\"all_jets_7_feature_point_cloud.npz\", X=all_jets, y=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e8dedf98-e96d-4d10-8e92-fbb25dcd0b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~10 sec\n",
    "N1 = 30000\n",
    "np.savez(f\"30k_jets_7_feature_point_cloud.npz\", X=all_jets[:N1], y=labels[:N1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "top-tagging",
   "language": "python",
   "name": "top-tagging"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

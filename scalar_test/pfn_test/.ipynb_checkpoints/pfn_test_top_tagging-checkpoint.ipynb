{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c8b613d-e95f-43c1-93b8-6646e0be5f54",
   "metadata": {},
   "source": [
    "# Particle Flow Test 1\n",
    "\n",
    "Make our own particle flow network, train it on top tagging dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b2625fc-9815-410c-a9a6-e636c6c07a5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Up to a minute to import everything\n",
    "# Make tensorflow quieter\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "# Computing imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "# Useful imports\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Energyflow imports\n",
    "import energyflow as ef\n",
    "from energyflow.utils import data_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b4b857-0f8d-484b-81d0-2183374b56e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import, preprocess data\n",
    "\n",
    "Data lives in `X_train`, `X_val`, `X_test`, and `Y_train`, `Y_val`, `Y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5acb3473-0268-4a28-96d5-b84c3a1a7ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data\n"
     ]
    }
   ],
   "source": [
    "# ~5 sec\n",
    "jets_path = \"/usatlas/atlas01/atlasdisk/users/atlas_wifeng/phys427/top-tagging/data/jets-988K-padded.npz\"\n",
    "jets = np.load(jets_path)\n",
    "\n",
    "X, y = jets[\"X\"], jets[\"y\"]\n",
    "Y = y\n",
    "\n",
    "print(\"Loaded data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b9a5fb0-9665-4758-9d2a-bdfe1eb6ec7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done train/val/test split\n"
     ]
    }
   ],
   "source": [
    "# Do train/val/test split\n",
    "n_val = 200000\n",
    "n_test = 200000\n",
    "\n",
    "(X_train, X_val, X_test,\n",
    " Y_train, Y_val, Y_test) = data_split(X, Y, val=n_val, test=n_test)\n",
    "\n",
    "print(\"Done train/val/test split\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ab3922-436a-41c0-bd40-83c4e4d5ad06",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df8f8ff-7dca-400f-b136-e8b99914ab03",
   "metadata": {},
   "source": [
    "PFN model:\n",
    "$$\\text{PFN}=F\\left(\\sum_{i=1}^M \\Phi(p_i)\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2018c05c-4e0d-4a4f-a80f-f26a5caa6515",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def PFN(n_features,\n",
    "        n_particles,\n",
    "        n_outputs,\n",
    "        Phi_sizes,\n",
    "        F_sizes,\n",
    "        name=None):\n",
    "    \n",
    "        inputs = layers.Input((n_particles, n_features), name=\"input\")    \n",
    "        masking_layer = layers.Masking(\n",
    "            mask_value=0.,\n",
    "            input_shape=(n_particles, n_features)\n",
    "        )\n",
    "        Phi_layers = [layers.Dense(size, activation=\"relu\", name=f\"Phi_{i}\") for i, size in enumerate(Phi_sizes)]\n",
    "        F_layers = [layers.Dense(size, activation=\"relu\", name=f\"F_{i}\") for i, size in enumerate(F_sizes)]\n",
    "        last_layer = layers.Dense(n_outputs, name=\"output\")\n",
    "        \n",
    "        x = masking_layer(inputs)\n",
    "        for layer in Phi_layers:\n",
    "            x = layers.TimeDistributed(layer)(x)\n",
    "        x = tf.math.reduce_sum(x, axis=1)\n",
    "        for layer in F_layers:\n",
    "            x = layer(x)\n",
    "        x = last_layer(x)\n",
    "        \n",
    "        return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad97813-563f-4004-8870-efe774e60fcf",
   "metadata": {},
   "source": [
    "## Compile and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e684b2cb-ce18-4876-a29b-4fe178659d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes about 5 sec\n",
    "\n",
    "# Training hyperparameters\n",
    "lr = 1e-3\n",
    "epochs = 5\n",
    "batch_size = 10\n",
    "\n",
    "# Data dimensions\n",
    "n_features = 5\n",
    "n_particles = 212\n",
    "\n",
    "model = PFN(\n",
    "    n_features=n_features,\n",
    "    n_particles=n_particles,\n",
    "    n_outputs=5,\n",
    "    Phi_sizes=[100, 100, 50],\n",
    "    F_sizes=[100, 100, 50]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3740305-7324-4aa9-a75d-130c900055d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'current': 171520, 'peak': 230144}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.config.experimental.get_memory_info(\"GPU:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64d6615b-ccde-496b-924f-f005075d9185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 212, 5)]          0         \n",
      "                                                                 \n",
      " masking (Masking)           (None, 212, 5)            0         \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 212, 100)         600       \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 212, 100)         10100     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 212, 50)          5050      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " tf.math.reduce_sum (TFOpLam  (None, 50)               0         \n",
      " bda)                                                            \n",
      "                                                                 \n",
      " F_0 (Dense)                 (None, 100)               5100      \n",
      "                                                                 \n",
      " F_1 (Dense)                 (None, 100)               10100     \n",
      "                                                                 \n",
      " F_2 (Dense)                 (None, 50)                5050      \n",
      "                                                                 \n",
      " output (Dense)              (None, 5)                 255       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36,255\n",
      "Trainable params: 36,255\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b465b5af-c447-4c40-a90b-35f83ed0140c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f49f8749-b841-425e-9d08-e1cc86c3f046",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usatlas/atlas01/atlasdisk/users/atlas_wifeng/sw/miniconda/envs/top-tagging/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usatlas/atlas01/atlasdisk/users/atlas_wifeng/sw/miniconda/envs/top-tagging/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:103\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    102\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train,\n",
    "                    epochs=5,\n",
    "                    batch_size=500,\n",
    "                    validation_data=(X_val, Y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e8e442-467b-40e6-a690-27b95f2830ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions on test data\n",
    "preds = model.predict(X_test, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b728b3-85be-4e41-bc53-54fd398fd828",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.argmax(Y_test, axis=1)\n",
    "pred_labels = np.argmax(preds, axis=1)\n",
    "\n",
    "mask = (test_labels == pred_labels).astype(float)\n",
    "print(mask)\n",
    "print(f\"Test accuracy: {mask.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f64d09-667d-45fb-8121-cfe52b46ad59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "top-tagging",
   "language": "python",
   "name": "top-tagging"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

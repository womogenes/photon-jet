{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "546cd4a9-f11e-4353-9be3-a3e2d2b1897f",
   "metadata": {},
   "source": [
    "## Aaaargh new data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938bc591-5a6d-43d1-a2cf-d48106d3b7e7",
   "metadata": {},
   "source": [
    "## Step 1: Export new training data for tasks as separate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed284de9-f484-4735-9e8d-ecdf3bcc4d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-29 01:59:17.287016: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from utils import data_dir\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9705f5b1-91e3-47db-b467-0fc351ed17bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"axion2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6771d1ce-3563-4cb7-9bec-8315a51eee54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_split(X, Y, n_test):\n",
    "    \"\"\"\n",
    "    Split X and Y (ndarrays where leading dimension is examples)\n",
    "    Returns a 6-tuple (X_train, X_test, Y_train, Y_test).\n",
    "    \"\"\"\n",
    "    assert(len(X) == len(Y)), \"X and Y should have same length.\"\n",
    "    assert(n_test < len(X)), \"n_test should comprise less than total.\"\n",
    "\n",
    "    N = len(X)\n",
    "    train = N - n_test\n",
    "    \n",
    "    X_train, Y_train = X[:train], Y[:train]\n",
    "    X_test, Y_test = X[train:], Y[train:]\n",
    "\n",
    "    return (X_train, X_test,\n",
    "            Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a30eb167-fbda-457a-880a-1ecc1d90fa1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data(task):\n",
    "    \"\"\"\n",
    "    Return 4-tuple of data.\n",
    "    task should be one of \"scalar1\", \"axion1\", or \"axion2\".\n",
    "    \"\"\"\n",
    "    cloud_paths = [\"pi0_cloud.npy\", \"gamma_cloud.npy\", f\"{task}_cloud.npy\"]\n",
    "    \n",
    "    print(f\"Fetching all clouds...\")\n",
    "    X = np.concatenate([\n",
    "        np.load(f\"{data_dir}/processed/{path}\") \\\n",
    "        for path in cloud_paths\n",
    "    ], axis=0)\n",
    "    \n",
    "    N = 100000  # Size of each dataset\n",
    "    assert(len(X) == 3 * N)  # Assumption about data size\n",
    "    \n",
    "    Y = to_categorical((0,) * N + (1,) * N + (2,) * N)\n",
    "    \n",
    "    # Scramble in the same order\n",
    "    print(f\"Scrambling order...\")\n",
    "    rng = np.random.default_rng(0)\n",
    "    permutation = np.random.permutation(3 * N)\n",
    "    X = X[permutation]\n",
    "    Y = Y[permutation]\n",
    "    \n",
    "    n_test = round(0.3 * 3 * N)\n",
    "    \n",
    "    return data_split(X, Y, n_test=n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dc5795b-b93e-4327-a3fe-c6689d9b65c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching all clouds...\n",
      "Scrambling order...\n"
     ]
    }
   ],
   "source": [
    "# ~40 sec\n",
    "(X_train, X_test, Y_train, Y_test) = get_data(task_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25582c34-1a44-4113-9da7-76ba71f87a00",
   "metadata": {},
   "source": [
    "## Use a different method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "658c0422-a105-4d28-bab9-dc1c4d9bde32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ccf37bb-bd33-4b3c-954f-8f80ea85cec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-29 02:00:12.348761: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 6451200000 exceeds 10% of free system memory.\n",
      "2023-10-29 02:00:16.702277: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 6451200000 exceeds 10% of free system memory.\n",
      "2023-10-29 02:00:35.694473: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2764800000 exceeds 10% of free system memory.\n",
      "2023-10-29 02:00:37.409059: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2764800000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "for name, arr in [(\"X_train\", X_train), (\"Y_train\", Y_train), \\\n",
    "                  (\"X_test\", X_test), (\"Y_test\", Y_test)]:\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(arr)\n",
    "    dataset.save(f\"{data_dir}/processed/tf_dataset/{task_name}/{name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
